import dart_fss as dart
import time

import os
import json
import traceback
import requests
import google.generativeai as genai
import FinanceDataReader as fdr
import pandas as pd
import numpy as np
import statistics
from flask import Blueprint, render_template, request, jsonify
from dotenv import load_dotenv
from datetime import datetime, timedelta

from pykrx import stock
import re
from bs4 import BeautifulSoup

TICKER_NAME_MAP = None
NAME_TICKER_MAP = None
load_dotenv()

askfin_bp = Blueprint('askfin', __name__, url_prefix='/askfin')
try:
    DART_API_KEY = os.getenv("DART_API_KEY")
    if not DART_API_KEY:
        raise ValueError("DART API í‚¤ê°€ .env íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.")
    dart.set_api_key(api_key=DART_API_KEY)
    print("DART API í‚¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
except Exception as e:
    print(f"[ê²½ê³ ] DART API í‚¤ ì„¤ì • ì‹¤íŒ¨: {e}")


try:
    API_KEY = os.getenv("GOOGLE_AI_API_KEY")
    if not API_KEY: raise ValueError("API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    genai.configure(api_key=API_KEY)
    model = genai.GenerativeModel('gemini-1.5-flash')

    PROMPT_TEMPLATE = """
You are a financial analyst. Your task is to analyze a user's query and convert it into a structured JSON object.
First, classify the query_type as "stock_analysis" or "indicator_lookup".

- "stock_analysis": For questions about stock performance under certain conditions.
- "indicator_lookup": For questions asking for a specific economic indicator's value.

- You MUST only respond with a JSON object. No other text.
- For a "condition" involving an indicator, use a condition object.

## JSON Schema:
{{"query_type": "stock_analysis|indicator_lookup", "period": "string|null", "condition": "string|object|null", "target": "string|null", "action": "string|null"}}

## Examples:
1. User Query: "ì§€ë‚œ 3ë…„ ë™ì•ˆ ê²¨ìš¸ì— ì˜¤ë¥¸ ì½˜í…ì¸  ê´€ë ¨ ì£¼ì‹"
   JSON Output:
   ```json
   {{"query_type": "stock_analysis", "period": "ì§€ë‚œ 3ë…„", "condition": "ê²¨ìš¸", "target": "ì½˜í…ì¸  ê´€ë ¨ì£¼", "action": "ì˜¤ë¥¸ ì£¼ì‹"}}
   
2. User Query: "ìµœê·¼ CPI ì§€ìˆ˜ ì•Œë ¤ì¤˜"
   JSON Output:
   ```json
    {{"query_type": "indicator_lookup", "period": "ìµœê·¼", "condition": null, "target": "CPI ì§€ìˆ˜", "action": "ì¡°íšŒ"}}
    ```

3.  User Query: "ì§€ë‚œ 3ë…„ ë™ì•ˆ ê²¨ìš¸ì— ì˜¤ë¥¸ ì½˜í…ì¸  ê´€ë ¨ ì£¼ì‹ì„ ë³´ì—¬ì¤˜"
    JSON Output:
    ```json
    {{"period": "ì§€ë‚œ 3ë…„","condition": "ê²¨ìš¸","target": "ì½˜í…ì¸  ê´€ë ¨ì£¼","action": "ì˜¤ë¥¸ ì£¼ì‹"}}

    ```
    
4. User Query: "ìµœê·¼ CPI ì§€ìˆ˜ê°€ 3.5%ë³´ë‹¤ ë†’ì•˜ì„ ë•Œ ê°€ì¥ ë§ì´ ì˜¤ë¥¸ ì£¼ì‹ì€?"
   JSON Output:
    ```json
    {{"period": "ìµœê·¼", "condition": {{"type": "indicator", "name": "CPI", "operator": ">", "value": 3.5}}, "target": "ì£¼ì‹", "action": "ê°€ì¥ ë§ì´ ì˜¤ë¥¸ ì£¼ì‹"}}

    ```

5. User Query: "ì§€ë‚œ 1ë…„ê°„ 2ì°¨ì „ì§€ì£¼ ì¤‘ ê°€ì¥ ë§ì´ ë‚´ë¦° ì£¼ì‹ì€?"
   JSON Output:
   ```json
   {{"query_type": "stock_analysis", "period": "ì§€ë‚œ 1ë…„ê°„", "condition": null, "target": "2ì°¨ì „ì§€ì£¼", "action": "ê°€ì¥ ë§ì´ ë‚´ë¦° ì£¼ì‹"}}

   
## Task:
User Query: "{user_query}"
JSON Output:
"""
except Exception as e:
    print(f"AskFin Blueprint: ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨ - {e}")
    model = None

# --- Helper Functions ---

def _load_ticker_maps():
    """ì¢…ëª© ì •ë³´ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ì„ ê²½ìš°ì—ë§Œ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    global TICKER_NAME_MAP, NAME_TICKER_MAP
    # ë§µì´ ë¹„ì–´ìˆì„ ë•Œë§Œ (ìµœì´ˆ í˜¸ì¶œ ì‹œ) ì‹¤í–‰
    if NAME_TICKER_MAP is None:
        print("ì§€ì—° ë¡œë”©: ì „ì²´ ì¢…ëª© ì½”ë“œ ë° ì´ë¦„ ë¡œë”©ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        all_tickers = stock.get_market_ticker_list(market="ALL")
        TICKER_NAME_MAP = {ticker: stock.get_market_ticker_name(ticker) for ticker in all_tickers}
        NAME_TICKER_MAP = {name: ticker for ticker, name in TICKER_NAME_MAP.items()}
        print("ì¢…ëª© ì •ë³´ ë¡œë”© ì™„ë£Œ.")

def _get_fdr_indicator(indicator_info, intent_json):
    """FinanceDataReaderë¥¼ í†µí•´ ì¼ë³„ ì§€í‘œë¥¼ ì¡°íšŒí•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    try:
        name = indicator_info['name']
        code = indicator_info['code']
        
        end_date = datetime.now()
        start_date = end_date - timedelta(days=60)
        data = fdr.DataReader(code, start_date, end_date)
        
        if data.empty or len(data) < 2:
            return {"error": f"{name} ë°ì´í„° ì¡°íšŒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}

        latest = data['Close'].iloc[-1]
        previous = data['Close'].iloc[-2]
        change = latest - previous
        change_str = f"{abs(change):.2f} ìƒìŠ¹" if change > 0 else f"{abs(change):.2f} í•˜ë½" if change < 0 else "ë³€ë™ ì—†ìŒ"
        latest_date = data.index[-1].strftime('%Yë…„ %mì›” %dì¼')
        
        result_sentence = f"ê°€ì¥ ìµœê·¼({latest_date}) {name}ëŠ”(ì€) {latest:,.2f}ì´ë©°, ì „ì¼ ëŒ€ë¹„ {change_str}í–ˆìŠµë‹ˆë‹¤."
        
        return {
            "query_intent": intent_json,
            "analysis_subject": name,
            "result": [result_sentence]
        }
    except Exception as e:
        return {"error": f"{indicator_info.get('name', 'ì•Œìˆ˜ì—†ëŠ”')} ì§€í‘œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"}

def _get_bok_indicator(indicator_info, intent_json):
    """í•œêµ­ì€í–‰(BOK) APIë¥¼ í†µí•´ ì›”ë³„ ì§€í‘œë¥¼ ì¡°íšŒí•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    try:
        name = indicator_info['name']
        bok_api_key = os.getenv("ECOS_API_KEY")
        if not bok_api_key: return {"error": "í•œêµ­ì€í–‰ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

        end_date = datetime.now().strftime('%Y%m')
        start_date = (datetime.now() - timedelta(days=120)).strftime('%Y%m')
        url = (f"https://ecos.bok.or.kr/api/StatisticSearch/{bok_api_key}/json/kr/1/10/"
               f"{indicator_info['stats_code']}/MM/{start_date}/{end_date}/{indicator_info['item_code']}")

        response = requests.get(url, timeout=10).json()
        rows = response.get("StatisticSearch", {}).get("row", [])
        
        if len(rows) < 2:
            return {"error": f"ìµœê·¼ {name} ë°ì´í„°ë¥¼ ë¹„êµí•  ë§Œí¼ ì¶©ë¶„íˆ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
        latest = rows[-1]
        previous = rows[-2]
        latest_date = f"{latest['TIME'][:4]}ë…„ {latest['TIME'][4:]}ì›”"
        change = float(latest['DATA_VALUE']) - float(previous['DATA_VALUE'])
        change_str = f"{abs(change):.2f} ìƒìŠ¹" if change > 0 else f"{abs(change):.2f} í•˜ë½" if change < 0 else "ë³€ë™ ì—†ìŒ"

        result_sentence = (f"ê°€ì¥ ìµœê·¼({latest_date}) {name}ëŠ”(ì€) {latest['DATA_VALUE']}ì´ë©°, ì „ì›” ëŒ€ë¹„ {change_str}í–ˆìŠµë‹ˆë‹¤.")
        
        return {
            "query_intent": intent_json,
            "analysis_subject": name,
            "result": [result_sentence]
        }
    except Exception as e:
        return {"error": f"í•œêµ­ì€í–‰(BOK) ì§€í‘œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"}


def execute_indicator_lookup(intent_json):
    """
    [ìµœì¢… ìˆ˜ì •] ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ê²½ì œ ì§€í‘œë¥¼ ì¡°íšŒí•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
    """
    target = intent_json.get("target", "")

    # ë°ì´í„° ì†ŒìŠ¤ 1: FinanceDataReader (ì¼ë³„ ë°ì´í„°)
    FDR_INDICATOR_MAP = {
        "í™˜ìœ¨": {"code": "USD/KRW", "name": "ì›/ë‹¬ëŸ¬ í™˜ìœ¨"},
        "ìœ ê°€": {"code": "WTI", "name": "WTI êµ­ì œ ìœ ê°€"},
        "ê¸ˆê°’": {"code": "GC", "name": "ê¸ˆ ì„ ë¬¼"},
        "ë¯¸êµ­ì±„10ë…„": {"code": "US10YT", "name": "ë¯¸ 10ë…„ë¬¼ êµ­ì±„ ê¸ˆë¦¬"},
        "ì½”ìŠ¤í”¼": {"code": "KS11", "name": "ì½”ìŠ¤í”¼ ì§€ìˆ˜"},
        "ì½”ìŠ¤ë‹¥": {"code": "KQ11", "name": "ì½”ìŠ¤ë‹¥ ì§€ìˆ˜"},
    }
    
    for key, value in FDR_INDICATOR_MAP.items():
        if key in target or value['name'] in target:
            return _get_fdr_indicator(value, intent_json)
            
    # ë°ì´í„° ì†ŒìŠ¤ 2: í•œêµ­ì€í–‰ ECOS (ì›”ë³„ ë°ì´í„°)
    BOK_INDICATOR_MAP = {
        "CPI": {"stats_code": "901Y001", "item_code": "0", "name": "ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜"},
        "ê¸°ì¤€ê¸ˆë¦¬": {"stats_code": "722Y001", "item_code": "0001000", "name": "í•œêµ­ ê¸°ì¤€ê¸ˆë¦¬"},
    }
    
    for key, value in BOK_INDICATOR_MAP.items():
        if key in target or value['name'] in target:
            return _get_bok_indicator(value, intent_json)

    # ì–´ë–¤ ë§µì—ì„œë„ ì°¾ì§€ ëª»í•œ ê²½ìš°
    return {
        "query_intent": intent_json,
        "analysis_subject": "ì•Œ ìˆ˜ ì—†ëŠ” ì§€í‘œ",
        "result": [f"'{target}' ì§€í‘œëŠ” ì•„ì§ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."]
    }

@askfin_bp.route('/stock/<code>/profile')
def get_stock_profile(code):
    """
    [ìµœì¢… ì™„ì„±] ì‹œì¥ ì •ë³´ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•˜ì—¬ ì¼ê´„ ì¡°íšŒí•¨ìœ¼ë¡œì¨
    ì•ˆì •ì„±ê³¼ ì†ë„ë¥¼ ëª¨ë‘ í™•ë³´í•œ ìµœì¢… API.
    """
    try:
        profile_data = {}
        latest_business_day = stock.get_nearest_business_day_in_a_week()

        # --- 1. fdrì—ì„œ ì¢…ëª©ì˜ ê¸°ë³¸ ì •ë³´ ë° ì†Œì† ì‹œì¥(Market) í™•ì¸ ---
        krx_list = fdr.StockListing('KRX')
        target_info = krx_list[krx_list['Code'] == code]
        if target_info.empty:
            return jsonify({"error": f"ì¢…ëª©ì½”ë“œ '{code}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        target_info = target_info.iloc[0]
        market = target_info.get('Market', 'KOSPI') # ê¸°ë³¸ê°’ KOSPI
        sector = target_info.get('Sector')
        
        profile_data['ê¸°ì—…ëª…'] = target_info.get('Name', 'N/A')
        profile_data['ì—…ì¢…'] = sector
        profile_data['ì£¼ìš”ì œí’ˆ'] = target_info.get('Industry', 'N/A')

        # --- 2. í™•ì¸ëœ ì‹œì¥(Market)ì˜ ë°ì´í„°ë¥¼ pykrxë¡œ ì¼ê´„ ì¡°íšŒ ---
        print(f"'{market}' ì‹œì¥ì˜ ì „ì²´ ë°ì´í„°ë¥¼ ì¼ê´„ ì¡°íšŒí•©ë‹ˆë‹¤...")
        df_ohlcv = stock.get_market_ohlcv(latest_business_day, market=market)
        df_cap = stock.get_market_cap(latest_business_day, market=market)
        df_funda = stock.get_market_fundamental(latest_business_day, market=market)
        print("ì¼ê´„ ì¡°íšŒ ì™„ë£Œ.")

        # --- 3. ì¼ê´„ ì¡°íšŒëœ ë°ì´í„°ì—ì„œ í•´ë‹¹ ì¢…ëª© ì •ë³´ ì¶”ì¶œ ---
        current_price = df_ohlcv.loc[code, 'ì¢…ê°€']
        market_cap = df_cap.loc[code, 'ì‹œê°€ì´ì•¡']
        funda = df_funda.loc[code]

        profile_data['í˜„ì¬ê°€'] = f"{current_price:,} ì›"
        if market_cap > 1_0000_0000_0000:
            profile_data['ì‹œê°€ì´ì•¡'] = f"{market_cap / 1_0000_0000_0000:.2f} ì¡°ì›"
        else:
            profile_data['ì‹œê°€ì´ì•¡'] = f"{market_cap / 1_0000_0000:.2f} ì–µì›"
        
        eps = funda.get('EPS', 0)
        per = funda.get('PER', 0)
        pbr = funda.get('PBR', 0)
        div = funda.get('DIV', 0)
        profile_data['PER'] = f"{per:.2f} ë°°" if per > 0 else "N/A"
        profile_data['PBR'] = f"{pbr:.2f} ë°°" if pbr > 0 else "N/A"
        profile_data['ë°°ë‹¹ìˆ˜ìµë¥ '] = f"{div:.2f} %" if div > 0 else "N/A"

        # --- 4. ì ì •ì£¼ê°€ ê³„ì‚° ---
        if sector and eps > 0:
            # ì—…ì¢… í‰ê·  PER ê³„ì‚°ì„ ìœ„í•´ krx_listì™€ df_fundaë¥¼ ë³‘í•©
            merged_df = krx_list.set_index('Code').join(df_funda)
            sector_pers = merged_df[merged_df['Sector'] == sector]['PER']
            sector_pers = sector_pers[sector_pers > 0]
            
            if not sector_pers.empty:
                avg_per = sector_pers.mean()
                fair_price = eps * avg_per
                upside = ((fair_price / current_price) - 1) * 100 if current_price > 0 else 0
                profile_data['ì ì •ì£¼ê°€(ì—…ì¢…PERê¸°ë°˜)'] = f"{int(fair_price):,} ì›"
                profile_data['ìƒìŠ¹ì—¬ë ¥'] = f"{upside:.2f} %"

        return jsonify({"company_profile": profile_data})

    except Exception as e:
        traceback.print_exc()
        return jsonify({"error": f"ê¸°ì—… ìƒì„¸ ì •ë³´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}), 500
    
def get_target_stocks(target_str):
    """íƒ€ê²Ÿ ë¬¸ìì—´ì— í•´ë‹¹í•˜ëŠ” ì¢…ëª© ë¦¬ìŠ¤íŠ¸(DataFrame)ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ (themes.json ì‚¬ìš©)"""
    
    GENERIC_TARGETS = {"ì£¼ì‹", "ì¢…ëª©", "ê¸‰ë“±ì£¼", "ìš°ëŸ‰ì£¼", "ì¸ê¸°ì£¼", "ì „ì²´"}
    print("KOSPI ë° KOSDAQ ì¢…ëª© ëª©ë¡ ë¡œë”© ì¤‘...")
    krx = fdr.StockListing('KRX')
    print("ì¢…ëª© ëª©ë¡ ë¡œë”© ì™„ë£Œ.")
    
    analysis_subject = "ì‹œì¥ ì „ì²´"
    target_stocks = krx

    if target_str and target_str.strip() and target_str not in GENERIC_TARGETS:
        analysis_subject = f"'{target_str}'"
        
        keyword = target_str.replace(" ê´€ë ¨ì£¼", "").replace(" í…Œë§ˆì£¼", "").replace(" í…Œë§ˆ", "").replace("ì£¼", "").strip()

        if keyword in THEME_MAP:
            print(f"í…Œë§ˆ '{keyword}'ì— ëŒ€í•œ ì¢…ëª©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
            theme_stock_names = THEME_MAP[keyword]
            _load_ticker_maps() 
            target_codes = [NAME_TICKER_MAP.get(name) for name in theme_stock_names if NAME_TICKER_MAP.get(name)]
            target_stocks = krx[krx['Code'].isin(target_codes)]
        
        else:
            print(f"ì¢…ëª©ëª…ì— '{keyword}' í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì¢…ëª©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
            target_stocks = krx[krx['Name'].str.contains(keyword, na=False)]
    
    elif target_str in GENERIC_TARGETS:
         analysis_subject = "ì‹œì¥ ì „ì²´"
            
    return target_stocks, analysis_subject


def parse_period(period_str):
    """'ì§€ë‚œ 3ë…„ê°„' ê°™ì€ ë¬¸ìì—´ì„ ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    today = datetime.now()
    if not period_str:
        return today - timedelta(days=365), today
    try:
        if "ë…„ê°„" in period_str:
            years = int(period_str.replace("ì§€ë‚œ", "").replace("ë…„ê°„", "").strip())
            return today - timedelta(days=365 * years), today
        elif "ê°œì›”" in period_str:
            months = int(period_str.replace("ì§€ë‚œ", "").replace("ê°œì›”", "").strip())
            return today - timedelta(days=30 * months), today
        elif "ì‘ë…„" in period_str:
            last_year = today.year - 1
            return datetime(last_year, 1, 1), datetime(last_year, 12, 31)
        elif "ì˜¬í•´" in period_str:
            return datetime(today.year, 1, 1), today
    except (ValueError, TypeError):
        pass

    return today - timedelta(days=365), today # ê¸°ë³¸ê°’: 1ë…„

def get_target_stocks(target_str):
    """íƒ€ê²Ÿ ë¬¸ìì—´ì— í•´ë‹¹í•˜ëŠ” ì¢…ëª© ë¦¬ìŠ¤íŠ¸(DataFrame)ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    
    THEME_MAP = {
        "ë°©ì‚°ì£¼": ['012450', '047810', '079550', '064350', '272210'],
    }

    GENERIC_TARGETS = {"ì£¼ì‹", "ì¢…ëª©", "ê¸‰ë“±ì£¼", "ìš°ëŸ‰ì£¼", "ì¸ê¸°ì£¼", "ì „ì²´"}
    print("KOSPI ë° KOSDAQ ì¢…ëª© ëª©ë¡ ë¡œë”© ì¤‘...")
    krx = fdr.StockListing('KRX')
    print("ì¢…ëª© ëª©ë¡ ë¡œë”© ì™„ë£Œ.")
    
    analysis_subject = "ì‹œì¥ ì „ì²´"
    target_stocks = krx

    if target_str and target_str.strip():
        analysis_subject = f"'{target_str}'"

        if target_str in THEME_MAP:
            print(f"í…Œë§ˆ '{target_str}'ì— ëŒ€í•œ ì¢…ëª©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
            target_codes = THEME_MAP[target_str]
            target_stocks = krx[krx['Code'].isin(target_codes)]
        
        elif target_str not in GENERIC_TARGETS:
            print(f"ì¢…ëª©ëª…ì— '{target_str}' í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì¢…ëª©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
            keyword = target_str.replace(" ê´€ë ¨ì£¼", "").replace("ì£¼", "")
            target_stocks = krx[krx['Name'].str.contains(keyword, na=False)]
        
        else:
            analysis_subject = "ì‹œì¥ ì „ì²´"
            target_stocks = krx
            
    return target_stocks, analysis_subject

def get_interest_rate_hike_dates(api_key):
    """í•œêµ­ì€í–‰ APIë¡œ ê¸°ì¤€ê¸ˆë¦¬ ì¸ìƒì¼ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜."""
    stats_code, item_code = "722Y001", "0001000"
    end_date = datetime.now().strftime('%Y%m%d')
    start_date = (datetime.now() - timedelta(days=5*365)).strftime('%Y%m%d')
    url = f"https://ecos.bok.or.kr/api/StatisticSearch/{api_key}/json/kr/1/1000/{stats_code}/DD/{start_date}/{end_date}/{item_code}"
    
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        if "StatisticSearch" not in data or "row" not in data.get("StatisticSearch", {}):
            return []

        df = pd.DataFrame(data["StatisticSearch"]["row"])
        df['TIME'] = pd.to_datetime(df['TIME'], format='%Y%m%d')
        df['DATA_VALUE'] = pd.to_numeric(df['DATA_VALUE'])
        df = df.sort_values(by='TIME').reset_index(drop=True)
        df['PREV_VALUE'] = df['DATA_VALUE'].shift(1)
        
        hike_dates = df[df['DATA_VALUE'] > df['PREV_VALUE']]['TIME'].tolist()
        return hike_dates
    except Exception as e:
        print(f"í•œêµ­ì€í–‰ API ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return []
    
def handle_season_condition(date_range, season):
    start_date, end_date = date_range
    start_year = int(start_date[:4])
    end_year = int(end_date[:4])
    
    periods = []

    for year in range(start_year, end_year + 1):
        if season == "ì—¬ë¦„":
            periods.append((f"{year}-06-01", f"{year}-08-31"))
        elif season == "ë´„":
            periods.append((f"{year}-03-01", f"{year}-05-31"))
        elif season == "ê°€ì„":
            periods.append((f"{year}-09-01", f"{year}-11-30"))
        elif season == "ê²¨ìš¸":
            periods.append((f"{year}-12-01", f"{year+1}-02-28"))
        else:
            periods.append((start_date, end_date))  # fallback

    return periods


def execute_stock_analysis(intent_json, page):
    """
    ì£¼ì‹ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ , í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ í‘œì¤€í™”ëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” ìµœì¢… í•¨ìˆ˜.
    """
    try:
        # 1. ì‚¬ìš©ì ì˜ë„(JSON)ì—ì„œ ë¶„ì„ì— í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
        target_str = intent_json.get("target")
        action_str = intent_json.get("action", "")
        condition_str = intent_json.get("condition")

        # 2. ë¶„ì„ ëŒ€ìƒ ì¢…ëª© ì„ ì •
        target_stocks, analysis_subject = get_target_stocks(target_str)
        if target_stocks.empty:
            return {"result": [f"{analysis_subject}ì— í•´ë‹¹í•˜ëŠ” ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]}

        # 3. ë¶„ì„ ê¸°ê°„ ë° ì¡°ê±´(ê³„ì ˆ ë“±)ì— ë”°ë¥¸ ì„¸ë¶€ ê¸°ê°„ ì„¤ì •
        start_date, end_date = parse_period(intent_json.get("period"))
        
        event_periods = []
        if isinstance(condition_str, str) and any(s in condition_str for s in ["ì—¬ë¦„", "ê²¨ìš¸"]):
            season = "ì—¬ë¦„" if "ì—¬ë¦„" in condition_str else "ê²¨ìš¸"
            event_periods = handle_season_condition((start_date, end_date), season)
        else:
            event_periods = [(start_date, end_date)]

        # 4. ì‚¬ìš©ìì˜ 'ì•¡ì…˜'ì— ë”°ë¼ ì ì ˆí•œ ë¶„ì„ í•¨ìˆ˜ í˜¸ì¶œ
        result_data = []
        if "ì˜¤ë¥¸" in action_str or "ë‚´ë¦°" in action_str:
            result_data = analyze_top_performers(target_stocks, event_periods, (start_date, end_date))
        elif "ë³€ë™ì„±" in action_str or "ë³€ë™" in action_str:
            result_data = analyze_volatility(target_stocks, (start_date, end_date))
        elif "ëª©í‘œì£¼ê°€" in action_str:
            result_data = analyze_target_price_upside(target_stocks)
        else:
            return {"error": f"'{action_str}' ì•¡ì…˜ì€ ì•„ì§ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}

        # 5. ë¶„ì„ ê²°ê³¼ ì •ë ¬
        reverse_sort = False if "ë‚´ë¦°" in action_str else True
        sorted_result = sorted(result_data, key=lambda x: x.get('value', -999), reverse=reverse_sort)
        
        # 6. í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬
        items_per_page = 20
        total_items = len(sorted_result)
        total_pages = (total_items + items_per_page - 1) // items_per_page
        start_index = (page - 1) * items_per_page
        end_index = start_index + items_per_page
        paginated_result = sorted_result[start_index:end_index]
        
        # 7. ìµœì¢… ê²°ê³¼ JSON êµ¬ì„±í•˜ì—¬ ë°˜í™˜
        return {
            "query_intent": intent_json,
            "analysis_subject": analysis_subject,
            "result": paginated_result,
            "pagination": {
                "current_page": page,
                "total_pages": total_pages,
                "total_items": total_items
            }
        }
    except Exception as e:
        traceback.print_exc()
        return {"error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}
    

def handle_season_condition(period_tuple, season):
    """'ì—¬ë¦„' ë˜ëŠ” 'ê²¨ìš¸' ì¡°ê±´ì— ë§ëŠ” ë‚ ì§œ êµ¬ê°„ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    start_date, end_date = period_tuple
    event_periods = []
    
    # ë¶„ì„í•  ê¸°ê°„ ë‚´ì˜ ëª¨ë“  ì—°ë„ë¥¼ ìˆœíšŒ
    for year in range(start_date.year, end_date.year + 1):
        season_start, season_end = None, None
        
        if season == "ê²¨ìš¸":

            dec_first_prev_year = datetime(year - 1, 12, 1)
            feb_last_this_year = datetime(year, 3, 1) - timedelta(days=1)
            if dec_first_prev_year <= end_date and feb_last_this_year >= start_date:
                event_periods.append((max(dec_first_prev_year, start_date), min(feb_last_this_year, end_date)))

        elif season == "ì—¬ë¦„":
            season_start = datetime(year, 6, 1)
            season_end = datetime(year, 8, 31)
            if season_start <= end_date and season_end >= start_date:
                event_periods.append((max(season_start, start_date), min(season_end, end_date)))

    return event_periods

def handle_interest_rate_condition(api_key, period_tuple):
    """ê¸ˆë¦¬ ì¸ìƒ ì¡°ê±´ì— ë§ëŠ” ë‚ ì§œ êµ¬ê°„ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    start_date, end_date = period_tuple
    hike_dates = get_interest_rate_hike_dates(api_key)
    
    event_periods = []
    for hike_date in hike_dates:
        event_start = hike_date
        event_end = event_start + timedelta(days=7)
        
        if event_start >= start_date and event_end <= end_date:
            event_periods.append((event_start, event_end))
            
    return event_periods

# askfin.py

def analyze_top_performers(target_stocks, event_periods, overall_period):
    """ìˆ˜ìµë¥  ë¶„ì„ í•¨ìˆ˜ (ë”œë ˆì´ ì¶”ê°€ë¡œ ì•ˆì •ì„± í™•ë³´)"""
    analysis_results = []
    top_stocks = target_stocks.nlargest(min(len(target_stocks), 100), 'Marcap').reset_index(drop=True)
    print(f"ì‹œê°€ì´ì•¡ ìƒìœ„ {len(top_stocks)}ê°œ ì¢…ëª©ì— ëŒ€í•œ ìˆ˜ìµë¥  ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    overall_start, overall_end = overall_period

    for index, stock in top_stocks.iterrows():
        stock_code, stock_name = stock['Code'], stock['Name']
        print(f"  ({index + 1}/{len(top_stocks)}) {stock_name}({stock_code}) ë¶„ì„ ì¤‘...")
        try:
            overall_prices = fdr.DataReader(stock_code, overall_start, overall_end)
            if overall_prices.empty:
                time.sleep(0.2) # ì‹¤íŒ¨ ì‹œì—ë„ ë”œë ˆì´
                continue
            
            start_price = overall_prices['Open'].iloc[0]
            end_price = overall_prices['Close'].iloc[-1]
            period_returns = []
            for start, end in event_periods:
                prices = fdr.DataReader(stock_code, start, end)
                if len(prices) > 1:
                    event_start_price = prices['Open'].iloc[0]
                    event_end_price = prices['Close'].iloc[-1]
                    if event_start_price > 0:
                        period_returns.append((event_end_price / event_start_price) - 1)
            
            if period_returns:
                average_return = statistics.mean(period_returns)
                if pd.notna(average_return):
                    analysis_results.append({
                        "code": stock_code,
                        "name": stock_name,
                        "value": round(average_return * 100, 2),
                        "label": "í‰ê·  ìˆ˜ìµë¥ (%)",
                        "start_price": int(start_price),
                        "end_price": int(end_price)
                    })
        except Exception as e:
            print(f"  - {stock_name}({stock_code}) ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            pass
        
        # --- ê° ì¢…ëª© ë¶„ì„ í›„ 0.2ì´ˆ ëŒ€ê¸° ---
        time.sleep(0.2)
            
    return analysis_results

def analyze_volatility(target_stocks, period_tuple):
    """ë³€ë™ì„± ë¶„ì„ í•¨ìˆ˜ (ë”œë ˆì´ ì¶”ê°€ë¡œ ì•ˆì •ì„± í™•ë³´)"""
    analysis_results = []
    start_date, end_date = period_tuple
    top_stocks = target_stocks.nlargest(min(len(target_stocks), 100), 'Marcap').reset_index(drop=True)
    print(f"ì‹œê°€ì´ì•¡ ìƒìœ„ {len(top_stocks)}ê°œ ì¢…ëª©ì— ëŒ€í•œ ë³€ë™ì„± ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    for index, stock_info in top_stocks.iterrows():
        code, name = stock_info['Code'], stock_info['Name']
        print(f"  ({index + 1}/{len(top_stocks)}) {name}({code}) ë¶„ì„ ì¤‘...")
        try:
            overall_prices = fdr.DataReader(code, start_date, end_date)
            if overall_prices.empty:
                time.sleep(0.2) # ì‹¤íŒ¨ ì‹œì—ë„ ë”œë ˆì´
                continue
            
            daily_returns = overall_prices['Close'].pct_change().dropna()
            volatility = daily_returns.std()
            if pd.notna(volatility):
                analysis_results.append({
                    "code": code, "name": name,
                    "value": round(volatility * 100, 2), "label": "ë³€ë™ì„±(%)",
                    "start_price": overall_prices['Open'].iloc[0],
                    "end_price": overall_prices['Close'].iloc[-1]
                })
        except Exception as e:
            print(f"  - {name}({code}) ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            pass
            
        # --- ê° ì¢…ëª© ë¶„ì„ í›„ 0.2ì´ˆ ëŒ€ê¸° ---
        time.sleep(0.2)
            
    return analysis_results

def handle_indicator_condition(condition_obj, period_tuple):
    """CPI, ê¸ˆë¦¬ ë“± ì§€í‘œ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë‚ ì§œ êµ¬ê°„ì„ ë°˜í™˜"""
    bok_api_key = os.getenv("ECOS_API_KEY")
    if not bok_api_key: return []
    INDICATOR_MAP = {
        "CPI": {"stats_code": "901Y001", "item_code": "0"},
        "ê¸°ì¤€ê¸ˆë¦¬": {"stats_code": "722Y001", "item_code": "0001000"},
    }

    indicator_name = condition_obj.get("name")
    if indicator_name not in INDICATOR_MAP: return []

    indicator_info = INDICATOR_MAP[indicator_name]
    data_series = get_bok_data(bok_api_key, indicator_info['stats_code'], indicator_info['item_code'], period_tuple[0], period_tuple[1])

    if data_series is None: return []

    op_str = condition_obj.get("operator")
    value = condition_obj.get("value")

    # ì¡°ê±´ì— ë§ëŠ” ë‚ ì§œ(ì›”) í•„í„°ë§
    if op_str == '>': matching_series = data_series[data_series > value]
    elif op_str == '>=': matching_series = data_series[data_series >= value]
    # ... ë‹¤ë¥¸ ì—°ì‚°ì ì¶”ê°€ ê°€ëŠ¥
    else: return []

    # í•´ë‹¹ ì›”ì˜ ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ì„ ë¶„ì„ êµ¬ê°„ìœ¼ë¡œ ì„¤ì •
    return [(d.replace(day=1), (d.replace(day=1) + timedelta(days=32)).replace(day=1) - timedelta(days=1)) for d in matching_series.index]

def get_bok_data(bok_api_key, stats_code, item_code, start_date, end_date):
    """
    í•œêµ­ì€í–‰ ECOS APIë¥¼ í†µí•´ íŠ¹ì • ì§€í‘œì˜ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ Pandas Seriesë¡œ ë°˜í™˜.
    """
    # BOK APIëŠ” YYYYMM í˜•ì‹ì˜ ì›”ë³„ ì¡°íšŒë¥¼ ì‚¬ìš©
    start_str = start_date.strftime('%Y%m')
    end_str = end_date.strftime('%Y%m')
    
    # API ìš”ì²­ URL (ìµœëŒ€ 1000ê°œ ë°ì´í„° ìš”ì²­)
    url = f"https://ecos.bok.or.kr/api/StatisticSearch/{bok_api_key}/json/kr/1/1000/{stats_code}/MM/{start_str}/{end_str}/{item_code}"
    
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()  # HTTP ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ë°œìƒ
        data = response.json()

        if "StatisticSearch" not in data or "row" not in data.get("StatisticSearch", {}):
            print("BOK API ì‘ë‹µì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        rows = data["StatisticSearch"]["row"]
        if not rows:
            return None

        df = pd.DataFrame(rows)
        df['TIME'] = pd.to_datetime(df['TIME'], format='%Y%m') 
        df['DATA_VALUE'] = pd.to_numeric(df['DATA_VALUE'])   
        df = df.set_index('TIME')                            
        
        return df['DATA_VALUE'].sort_index()

    except requests.exceptions.RequestException as e:
        print(f"í•œêµ­ì€í–‰ API ìš”ì²­ ì˜¤ë¥˜: {e}")
        return None
    except Exception as e:
        print(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None
    
@askfin_bp.route('/')
def askfin_page():
    return render_template('askfin.html')

QUERY_CACHE = {}

@askfin_bp.route('/analyze', methods=['POST'])
def analyze_query():
    """
    [ìµœì¢… ìˆ˜ì •] AI ì‘ë‹µì—ì„œ JSONì„ ë” ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ë„ë¡ ìˆ˜ì •í•œ API.
    """
    if not model:
        return jsonify({"error": "ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”."}), 500
    
    data = request.get_json()
    if not data or 'query' not in data:
        return jsonify({"error": "ì˜ëª»ëœ ìš”ì²­ì…ë‹ˆë‹¤."}), 400

    user_query = data['query']
    page = data.get('page', 1)

    try:
        # ìºì‹± ë¡œì§ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
        if user_query in QUERY_CACHE:
            print(f"âœ… CACHE HIT: '{user_query}'ì— ëŒ€í•œ ìºì‹œëœ ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            intent_json = QUERY_CACHE[user_query]
        else:
            print(f"ğŸ”¥ CACHE MISS: '{user_query}'ì— ëŒ€í•´ Gemini APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.")
            prompt = PROMPT_TEMPLATE.format(user_query=user_query)
            response = model.generate_content(prompt)

            # --- â–¼â–¼â–¼ JSON ì¶”ì¶œ ë° ì •ì œ ë¡œì§ ê°•í™” â–¼â–¼â–¼ ---
            raw_text = response.text
            # ë¬¸ìì—´ì—ì„œ ì²« '{'ì™€ ë§ˆì§€ë§‰ '}'ë¥¼ ì°¾ì•„ ê·¸ ì‚¬ì´ì˜ ë‚´ìš©ë§Œ ì¶”ì¶œ
            try:
                start = raw_text.find('{')
                end = raw_text.rfind('}') + 1
                cleaned_response = raw_text[start:end]
            except Exception:
                cleaned_response = ""
            # --- â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–² ---

            if not cleaned_response or not cleaned_response.startswith('{'):
                print(f"âŒ Geminiê°€ ìœ íš¨í•œ JSONì„ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‘ë‹µ: '{raw_text}'")
                return jsonify({"error": "AIê°€ ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ê±°ë‚˜ ë¶€ì ì ˆí•œ ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."})
            
            intent_json = json.loads(cleaned_response)
            QUERY_CACHE[user_query] = intent_json
        
        query_type = intent_json.get("query_type")
        
        final_result = {}
        if query_type == "stock_analysis":
            final_result = execute_stock_analysis(intent_json, page)
        elif query_type == "indicator_lookup":
            final_result = execute_indicator_lookup(intent_json)
        else:
            final_result = {"error": f"ì•Œ ìˆ˜ ì—†ëŠ” ì§ˆë¬¸ ìœ í˜•ì…ë‹ˆë‹¤: {query_type}"}
            
        return jsonify(final_result)

    except Exception as e:
        traceback.print_exc()
        return jsonify({"error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}), 500

@askfin_bp.route('/new_chat', methods=['POST'])
def new_chat():
    """ëŒ€í™” ê¸°ë¡(ì„¸ì…˜)ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    session.pop('chat_history', None)
    return jsonify({"status": "success", "message": "ìƒˆ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."})